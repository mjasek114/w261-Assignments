{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 DATASCI W261: Machine Learning at Scale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* **Name:**  Megan Jasek\n",
    "* **Email:**  meganjasek@ischool.berkeley.edu\n",
    "* **Class Name:**  W261-2\n",
    "* **Week Number:**  2\n",
    "* **Date:**  5/23/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW2.1.** Sort in Hadoop MapReduce.  **Given as input:** Records of the form (integer, “NA”), where integer is any integer, and “NA” is just the empty string.  **Output:** sorted key value pairs of the form (integer, “NA”) in decreasing order; what happens if you have multiple reducers? Do you need additional steps? Explain.\n",
    "\n",
    "**Part 1** Write code to generate N  random records of the form (integer, “NA”). Let N = 10,000.\n",
    "\n",
    "**Part 2** Write the python Hadoop streaming map-reduce job to perform this sort. Display the top 10 biggest numbers. Display the 10 smallest numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "N=10000\n",
    "min_int = -100000\n",
    "max_int = 100000\n",
    "filename = \"random_integers.txt\"\n",
    "with open(filename, 'w') as f:\n",
    "    for i in range(N):\n",
    "        f.write('<%d, \"\">\\n' % (random.randint(min_int, max_int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Arguments Given!\r\n",
      "Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar [options]\r\n",
      "Options:\r\n",
      "  dumptb <glob-pattern> Dumps all files that match the given pattern to \r\n",
      "                        standard output as typed bytes.\r\n",
      "  loadtb <path> Reads typed bytes from standard input and stores them in\r\n",
      "                a sequence file in the specified path\r\n",
      "  [streamjob] <args> Runs streaming job with given arguments\r\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/hadoop/bin/hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar \\\n",
    "-files /home/hadoop/mapper.py,/home/hadoop/reducer.py -mapper /home/hadoop/mapper.py \\\n",
    "-reducer /home/hadoop/reducer.py -input /user/hadoop/gutenberg/* -output /user/hadoop/gutenberg-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2.7.1.jar \\\n",
    "-files /home/hadoop/mapper.py,/home/hadoop/reducer.py -mapper /home/hadoop/mapper.py \\\n",
    "-reducer /home/hadoop/reducer.py -input /user/hadoop/gutenberg/* -output /user/hadoop/gutenberg-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
