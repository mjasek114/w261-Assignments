{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MidTerm DATASCI W261: Machine Learning at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Megan Jasek  \n",
    "**Email:** meganjasek@ischool.berkeley.edu  \n",
    "**Class Name:** W261-2  \n",
    "**Week Number:** 8, MidTerm Exam  \n",
    "**Date:** 6/29/16  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRJob for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Kmeans.py\n",
    "from numpy import argmin, array, random\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from itertools import chain\n",
    "\n",
    "#Calculate find the nearest centroid for data point \n",
    "def MinDist(datapoint, centroid_points):\n",
    "    D = datapoint\n",
    "    sqx1 = D[0]*D[0]\n",
    "    sqx2 = D[1]*D[1]\n",
    "    size_x = pow((sqx1+sqx2), 0.5)\n",
    "    weight = 1.0 / size_x\n",
    "    datapoint = array(datapoint)\n",
    "    centroid_points = array(centroid_points)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = weight*diff**2\n",
    "    \n",
    "    distances = (diffsq.sum(axis = 1))**0.5\n",
    "    # Get the nearest centroid for each instance\n",
    "    min_idx = argmin(distances)\n",
    "    return min_idx\n",
    "\n",
    "#Check whether centroids converge\n",
    "def stop_criterion(centroid_points_old, centroid_points_new,T):\n",
    "    oldvalue = list(chain(*centroid_points_old))\n",
    "    newvalue = list(chain(*centroid_points_new))\n",
    "    Diff = [abs(x-y) for x, y in zip(oldvalue, newvalue)]\n",
    "    Flag = True\n",
    "    for i in Diff:\n",
    "        if(i>T):\n",
    "            Flag = False\n",
    "            break\n",
    "    return Flag\n",
    "\n",
    "\n",
    "class MRKmeans(MRJob):\n",
    "    centroid_points=[]\n",
    "    k=3    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper_init = self.mapper_init, mapper=self.mapper,combiner = self.combiner,reducer=self.reducer)\n",
    "               ]\n",
    "    #load centroids info from file\n",
    "    def mapper_init(self):\n",
    "        self.centroid_points = [map(float,s.split('\\n')[0].split(',')) for s in open(\"Centroids.txt\").readlines()]\n",
    "        #open('Centroids.txt', 'w').close()\n",
    "    \n",
    "    #Weight each example as follows using the inverse vector length (Euclidean norm): \n",
    "    #weight(X)= 1/||X||, \n",
    "    #where ||X|| = SQRT(X.X)= SQRT(X1^2 + X2^2)\n",
    "    #Here X is vector made up of X1 and X2.\n",
    "    #load data and output the nearest centroid index and data point \n",
    "    def mapper(self, _, line):\n",
    "        #read in the data point\n",
    "        D = (map(float,line.split(',')))\n",
    "        # calculate the weights\n",
    "        sqx1 = D[0]*D[0]\n",
    "        sqx2 = D[1]*D[1]\n",
    "        size_x = pow((sqx1+sqx2), 0.5)\n",
    "        weight = 1.0 / size_x\n",
    "        weighted_D = [D[0], D[1]*weight]\n",
    "        #print D\n",
    "        #print weight\n",
    "        #print weighted_D\n",
    "        idx = MinDist(D,self.centroid_points)\n",
    "        #idx = MinDist(weighted_D, self.centroid_points)\n",
    "        yield int(idx), (D[0],D[1],1)\n",
    "    #Combine sum of data points locally\n",
    "    def combiner(self, idx, inputdata):\n",
    "        sumx = sumy = num = 0\n",
    "        for x,y,n in inputdata:\n",
    "            num = num + n\n",
    "            sumx = sumx + x\n",
    "            sumy = sumy + y\n",
    "        yield int(idx),(sumx,sumy,num)\n",
    "    #Aggregate sum for each cluster and then calculate the new centroids\n",
    "    def reducer(self, idx, inputdata): \n",
    "        centroids = []\n",
    "        num = [0]*self.k \n",
    "        distances = 0\n",
    "        for i in range(self.k):\n",
    "            centroids.append([0,0])\n",
    "        for x, y, n in inputdata:\n",
    "            num[idx] = num[idx] + n\n",
    "            centroids[idx][0] = centroids[idx][0] + x\n",
    "            centroids[idx][1] = centroids[idx][1] + y\n",
    "        centroids[idx][0] = centroids[idx][0]/num[idx]\n",
    "        centroids[idx][1] = centroids[idx][1]/num[idx]\n",
    "        yield idx,(centroids[idx][0],centroids[idx][1])\n",
    "        \n",
    "    # from HW4 for reference\n",
    "    #def reducer2(self, idx, inputdata): \n",
    "    #    centroids = []\n",
    "    #    num = [0]*self.k \n",
    "    #    for i in range(self.k):\n",
    "    #        centroids.append([0.0]*1000)\n",
    "    #    for D, n in inputdata:\n",
    "    #        num[idx] = num[idx] + n\n",
    "    #        centroids[idx] = [x + y for x, y in zip(centroids[idx],D)]\n",
    "    #    centroids[idx] = [i / float(num[idx]) for i in centroids[idx]]        \n",
    "    #    yield idx, centroids[idx]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRKmeans.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Driver:**  \n",
    "Generate random initial centroids  \n",
    "\n",
    "New Centroids = initial centroids  \n",
    "\n",
    "While(1):  \n",
    "\n",
    "* Cacluate new centroids\n",
    "* stop if new centroids close to old centroids\n",
    "* Updates centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1:\n",
      "2 [0.24288276270220563, 5.350519186138149]\n",
      "0 [-3.344726378997632, 0.3375985510805805]\n",
      "1 [5.379067911319121, 0.15446805295171434]\n",
      "\n",
      "\n",
      "iteration2:\n",
      "2 [0.08609737928171646, 5.025145679728709]\n",
      "0 [-4.938524015701949, 0.0432165878871746]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration3:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration4:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration5:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration6:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration7:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration8:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration9:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "iteration10:\n",
      "2 [0.053065423788147964, 4.987793423944292]\n",
      "0 [-4.98580568889943, 0.0009376094363626959]\n",
      "1 [5.0402327160888465, -0.026294229978289455]\n",
      "\n",
      "\n",
      "Centroids\n",
      "\n",
      "[[-4.98580568889943, 0.0009376094363626959], [5.0402327160888465, -0.026294229978289455], [0.053065423788147964, 4.987793423944292]]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from numpy import random, array\n",
    "from Kmeans import MRKmeans, stop_criterion\n",
    "mr_job = MRKmeans(args=['Kmeandata.csv', '--file=Centroids.txt'])\n",
    "#mr_job = MRKmeans(args=['Kmeandata_small.csv', '--file=Centroids.txt'])\n",
    "\n",
    "#Geneate initial centroids\n",
    "centroid_points = [[0,0],[6,3],[3,6]]\n",
    "k = 3\n",
    "with open('Centroids.txt', 'w+') as f:\n",
    "        f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "\n",
    "# Update centroids iteratively\n",
    "for i in range(10):\n",
    "    # save previous centoids to check convergency\n",
    "    centroid_points_old = centroid_points[:]\n",
    "    print \"iteration\"+str(i+1)+\":\"\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        # stream_output: get access of the output \n",
    "        for line in runner.stream_output():\n",
    "            key,value =  mr_job.parse_output_line(line)\n",
    "            print key, value\n",
    "            centroid_points[key] = value\n",
    "    with open('Centroids.txt', 'w+') as f:\n",
    "        f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "    print \"\\n\"\n",
    "    i = i + 1\n",
    "print \"Centroids\\n\"\n",
    "print centroid_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the MRJob Class below calculate the KL divergence of the following two objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kltext.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile kltext.txt\n",
    "1.Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from large volumes of data in various forms (data in various forms, data in various forms, data in various forms), either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, data mining and predictive analytics, as well as Knowledge Discovery in Databases.\n",
    "2.Machine learning is a subfield of computer science[1] that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[2] Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,[3]:2 rather than following strictly static program instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681098"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kldivergence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kldivergence.py\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "class kldivergence(MRJob):\n",
    "    def mapper1(self, _, line):\n",
    "        index = int(line.split('.',1)[0])\n",
    "        letter_list = re.sub(r\"[^A-Za-z]+\", '', line).lower()\n",
    "        count = {}\n",
    "        for l in letter_list:\n",
    "            if count.has_key(l):\n",
    "                count[l] += 1\n",
    "            else:\n",
    "                count[l] = 1\n",
    "        for key in count:\n",
    "            print key\n",
    "            print [index, count[key]*1.0/len(letter_list)]\n",
    "            yield key, [index, count[key]*1.0/len(letter_list)]\n",
    "\n",
    "\n",
    "    def reducer1(self, key, values):\n",
    "        #Fill in your code\n",
    "        # (P(i) log (P(i) / Q(i))\n",
    "        # a [1, 0.11078717201166181]\n",
    "        kl_sum = 0\n",
    "        for value in values:\n",
    "            v1 = value[0]\n",
    "            v2 = value[1]\n",
    "            kl_sum += v1 * math.log(v1/1.0*v2)\n",
    "        yield key, kl_sum\n",
    "    \n",
    "    def reducer2(self, key, values):\n",
    "        kl_sum = 0\n",
    "        for value in values:\n",
    "            kl_sum = kl_sum + value\n",
    "        yield None, kl_sum\n",
    "            \n",
    "    def steps(self):\n",
    "        return [self.mr(mapper=self.mapper1,\n",
    "                        reducer=self.reducer1),\n",
    "                self.mr(reducer=self.reducer2)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kldivergence.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "[1, 0.11078717201166181]\n",
      "c\n",
      "[1, 0.04081632653061224]\n",
      "b\n",
      "[1, 0.0058309037900874635]\n",
      "e\n",
      "[1, 0.07580174927113703]\n",
      "d\n",
      "[1, 0.05539358600583091]\n",
      "g\n",
      "[1, 0.014577259475218658]\n",
      "f\n",
      "[1, 0.029154518950437316]\n",
      "i\n",
      "[1, 0.09620991253644315]\n",
      "h\n",
      "[1, 0.01749271137026239]\n",
      "k\n",
      "[1, 0.0058309037900874635]\n",
      "m\n",
      "[1, 0.026239067055393587]\n",
      "l\n",
      "[1, 0.03206997084548105]\n",
      "o\n",
      "[1, 0.06997084548104957]\n",
      "n\n",
      "[1, 0.0641399416909621]\n",
      "p\n",
      "[1, 0.008746355685131196]\n",
      "s\n",
      "[1, 0.11078717201166181]\n",
      "r\n",
      "[1, 0.06705539358600583]\n",
      "u\n",
      "[1, 0.037900874635568516]\n",
      "t\n",
      "[1, 0.08163265306122448]\n",
      "w\n",
      "[1, 0.011661807580174927]\n",
      "v\n",
      "[1, 0.02040816326530612]\n",
      "y\n",
      "[1, 0.014577259475218658]\n",
      "x\n",
      "[1, 0.0029154518950437317]\n",
      "a\n",
      "[2, 0.08483290488431877]\n",
      "c\n",
      "[2, 0.04884318766066838]\n",
      "b\n",
      "[2, 0.007712082262210797]\n",
      "e\n",
      "[2, 0.08997429305912596]\n",
      "d\n",
      "[2, 0.04113110539845758]\n",
      "g\n",
      "[2, 0.02570694087403599]\n",
      "f\n",
      "[2, 0.02313624678663239]\n",
      "i\n",
      "[2, 0.09254498714652956]\n",
      "h\n",
      "[2, 0.030848329048843187]\n",
      "k\n",
      "[2, 0.005141388174807198]\n",
      "m\n",
      "[2, 0.03598971722365039]\n",
      "l\n",
      "[2, 0.04884318766066838]\n",
      "o\n",
      "[2, 0.07969151670951156]\n",
      "n\n",
      "[2, 0.08997429305912596]\n",
      "p\n",
      "[2, 0.02570694087403599]\n",
      "s\n",
      "[2, 0.04884318766066838]\n",
      "r\n",
      "[2, 0.07455012853470437]\n",
      "u\n",
      "[2, 0.02570694087403599]\n",
      "t\n",
      "[2, 0.09254498714652956]\n",
      "w\n",
      "[2, 0.002570694087403599]\n",
      "v\n",
      "[2, 0.007712082262210797]\n",
      "y\n",
      "[2, 0.012853470437017995]\n",
      "x\n",
      "[2, 0.005141388174807198]\n",
      "(None, -6.176856196945798)\n",
      "(None, -6.3325665339647035)\n",
      "(None, -10.67481229862674)\n",
      "(None, -6.508508897380844)\n",
      "(None, -6.852130655223675)\n",
      "(None, -5.879352386195518)\n",
      "(None, -9.208475229833315)\n",
      "(None, -12.23546004689141)\n",
      "(None, -14.992300412163052)\n",
      "(None, -14.992300412163052)\n",
      "(None, -11.55028103598064)\n",
      "(None, -5.747993490623596)\n",
      "(None, -13.488223015386778)\n",
      "(None, -7.850659485334803)\n",
      "(None, -7.888978349636939)\n",
      "(None, -6.009802112282632)\n",
      "(None, -9.681560525616458)\n",
      "(None, -10.163986674860752)\n",
      "(None, -9.617022004478887)\n",
      "(None, -5.715049334904242)\n",
      "(None, -14.299153231603107)\n",
      "(None, -8.09182154215169)\n",
      "(None, -8.903255536716205)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from kldivergence import kldivergence\n",
    "mr_job = kldivergence(args=['kltext.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
